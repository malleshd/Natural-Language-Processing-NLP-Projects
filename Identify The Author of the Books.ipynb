{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify The Author of the Books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to use consists of sentences from thousands of books of 10 authors. The idea is to train our machine to predict which author has written a specific sentence. This is an NLP classification problem where the objective is to classify each sentence based on who wrote it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They have been pronounced by an\\r\\n\\r\\n\\r\\n\\r\\...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His partner sailed along in\\r\\n\\r\\n\\r\\n\\r\\n\\r\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cushions were a good deal higher\\r\\n\\r\\n\\r...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O God, grant that in his presence I may\\r\\n\\r\\...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The grass\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nglowed with brigh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  They have been pronounced by an\\r\\n\\r\\n\\r\\n\\r\\...       2\n",
       "1  His partner sailed along in\\r\\n\\r\\n\\r\\n\\r\\n\\r\\...       0\n",
       "2  The cushions were a good deal higher\\r\\n\\r\\n\\r...       5\n",
       "3  O God, grant that in his presence I may\\r\\n\\r\\...       4\n",
       "4  The grass\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nglowed with brigh...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18977 entries, 0 to 18976\n",
      "Data columns (total 2 columns):\n",
      "text      18977 non-null object\n",
      "author    18977 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 296.6+ KB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18977, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\malle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []                                           # List for storing cleaned data\n",
    "ps = PorterStemmer()                                  # Initializing object for stemming\n",
    "\n",
    "##for i in range(0,1000):                             \n",
    "for i in range(len(ds)):                              # for each obervation in the dataset\n",
    "    text = re.sub('[^a-z A-Z]', ' ', ds['text'][i])   # Removing special characters\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))] #Stemming and removing stop words\n",
    "    text = ' '.join(text)                              # Joining all the cleaned words to form a sentence\n",
    "    corpus.append(text)                                #Adding the cleaned sentence to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pronounc expert rare varieti consider valu see handsom open flat box spoke show six finest pearl ever seen statement interest said sherlock holm anyth els occur ye later day come morn receiv letter perhap read thank said holm envelop pleas postmark london w date juli hum man thumb mark corner probabl postman best qualiti paper envelop sixpenc packet particular man stationeri',\n",
       " 'partner sail along front though notic noth medic student realli danc head excit frantic enthusiasm stamp shriek delight short absenc constraint mark ivan ilyitch wine begin affect began smile degre bitter doubt began steal heart cours like free easi manner unconvention desir even inwardli pray free easi manner held back unconvention gone beyond limit one ladi instanc one shabbi dark blue velvet dress bought fourth hand sixth figur pin dress turn someth like trouser kleopatra semyonovna one could ventur anyth partner medic student express medic student defi descript simpli fokin held back quickli emancip one might think noth transform somehow strang indic someth though forgotten ivan ilyitch exist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Count Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = ds.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18977, 1500)\n",
      "-------------------------------\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print('-------------------------------')\n",
    "print(X[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18977,)\n",
      "-------------------------------\n",
      "[2 0]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print('-------------------------------')\n",
    "print(y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malle\\ANACONDAInstall\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1 =SVC()\n",
    "classifier1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the author (by SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier1.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model (by SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Confusion Matrix \n",
      " [[689   2  19   2  76  24   7  19   5  29]\n",
      " [  0  91   0   1   0   0   3   2   0   0]\n",
      " [  7   1 493   4   0  10   0   7  12   3]\n",
      " [  0   0   0 223   0   0   0   0   0   0]\n",
      " [  5   0   0   1 562   5   1   6   0   6]\n",
      " [ 32  15  50   5  33 647   5  24  22  41]\n",
      " [  2   0   0   0   2   0 133   0   0   0]\n",
      " [  0   5   0   0   1   0   1 168   0   0]\n",
      " [  1   0   0   0   0   3   0   0 125   0]\n",
      " [  4   1   0   1   4   6   2   2   0 146]]\n",
      "--------------------------------------------------------\n",
      "Accuracy Score \n",
      " 0.863277133825079\n",
      "--------------------------------------------------------\n",
      "Accuracy Score \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85       872\n",
      "           1       0.79      0.94      0.86        97\n",
      "           2       0.88      0.92      0.90       537\n",
      "           3       0.94      1.00      0.97       223\n",
      "           4       0.83      0.96      0.89       586\n",
      "           5       0.93      0.74      0.82       874\n",
      "           6       0.88      0.97      0.92       137\n",
      "           7       0.74      0.96      0.83       175\n",
      "           8       0.76      0.97      0.85       129\n",
      "           9       0.65      0.88      0.75       166\n",
      "\n",
      "    accuracy                           0.86      3796\n",
      "   macro avg       0.83      0.91      0.86      3796\n",
      "weighted avg       0.88      0.86      0.86      3796\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------------')\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_pred, y_val))\n",
    "print('--------------------------------------------------------')\n",
    "print('Accuracy Score \\n', accuracy_score(y_pred, y_val))\n",
    "print('--------------------------------------------------------')\n",
    "print('Accuracy Score \\n', classification_report(y_pred, y_val))\n",
    "print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Naive Bayes to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier2 = GaussianNB()\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Evaluations (by NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier2.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Confusion Matrix \n",
      " [[576   0   4   0  65  25   0   5   0   3]\n",
      " [ 14  97   8   1  13  42   9  55   2  14]\n",
      " [ 30   0 490   0  20  96   0   8  16   6]\n",
      " [ 11   0   7 227  20  48   0   1   7   6]\n",
      " [ 30   2   1   1 473   4   2   2   0   0]\n",
      " [  4   2  20   6  10 344   0   7   7   1]\n",
      " [ 28   8   2   0  30  21 136  15   0  11]\n",
      " [  4   5   4   0   6  12   0 124   1   1]\n",
      " [  3   0  16   2   9  26   1   3 130   4]\n",
      " [ 40   1  10   0  32  77   4   8   1 179]]\n",
      "--------------------------------------------------------\n",
      "Accuracy Score \n",
      " 0.7312961011591148\n",
      "--------------------------------------------------------\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       678\n",
      "           1       0.84      0.38      0.52       255\n",
      "           2       0.87      0.74      0.80       666\n",
      "           3       0.96      0.69      0.80       327\n",
      "           4       0.70      0.92      0.79       515\n",
      "           5       0.49      0.86      0.63       401\n",
      "           6       0.89      0.54      0.67       251\n",
      "           7       0.54      0.79      0.64       157\n",
      "           8       0.79      0.67      0.73       194\n",
      "           9       0.80      0.51      0.62       352\n",
      "\n",
      "    accuracy                           0.73      3796\n",
      "   macro avg       0.77      0.69      0.70      3796\n",
      "weighted avg       0.77      0.73      0.73      3796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print('Confusion Matrix \\n', confusion_matrix(y_pred, y_val))\n",
    "print('--------------------------------------------------------')\n",
    "print('Accuracy Score \\n', accuracy_score(y_pred, y_val))\n",
    "print('--------------------------------------------------------')\n",
    "print('Classification Report \\n', classification_report(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC model has better Accuracy (0.863) compared to NB (0.731)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
